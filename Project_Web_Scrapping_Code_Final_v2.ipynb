{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen, Request\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "#For example county = Alameda\n",
    "#https://www.redfin.com/county/303/CA/Alameda-County/new-listings\n",
    "def getCountyUrls():\n",
    "    home_page = Request('https://www.redfin.com/sitemap/CA/newest-homes', headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    htmltext = urlopen(home_page).read()\n",
    "    home_page_soup = BS(htmltext,'html.parser')\n",
    "    county_urls = []\n",
    "    \n",
    "    for c_url in home_page_soup.findAll('a', attrs={'href': re.compile(\"^\\/county\")}):\n",
    "    #for c_url in home_page_soup.findAll('a', attrs={'href': re.compile(\"^\\/county/303/CA\")}):\n",
    "        c_url= c_url.get('href')\n",
    "        c_url= \"https://www.redfin.com\"+c_url\n",
    "        county_urls.append(c_url)\n",
    "    return (county_urls) #36 urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.redfin.com/CA/San-Leandro/661-Lee-Ave-94577/home/762354\n",
    "def getDetailUrls_NewListings(c_url_list):\n",
    "    detail_urls = []\n",
    "    \n",
    "    #https://www.redfin.com/county/303/CA/Alameda-County/new-listings\n",
    "    for c_url in c_url_list:\n",
    "        for page_no in range(1,6):\n",
    "            temp_url=c_url\n",
    "            if page_no>1:\n",
    "                temp_url = temp_url+\"/page-\"+str(page_no)\n",
    "            home_page = Request(temp_url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "            htmltext = urlopen(home_page).read()\n",
    "            home_page_soup = BS(htmltext,'html.parser')\n",
    "        \n",
    "            for d_url in home_page_soup.findAll('a', attrs={'href': re.compile(\"^\\/CA\")}):\n",
    "                d_url = d_url.get('href')\n",
    "                d_url = \"https://www.redfin.com\"+d_url\n",
    "                if (d_url not in detail_urls):\n",
    "                    detail_urls.append(d_url)\n",
    "    return (detail_urls) #returns 100 d_urls for each county (for 5 pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDetailUrls_SoldProperty(c_url_list):\n",
    "    detail_urls = []\n",
    "    \n",
    "    #https://www.redfin.com/county/303/CA/Alameda-County/new-listings\n",
    "    for c_url in c_url_list:\n",
    "        c_url = c_url+'filter/include=sold-3mo'\n",
    "        for page_no in range(1,6):\n",
    "            temp_url=c_url\n",
    "            if page_no>1:\n",
    "                temp_url = temp_url+\"/page-\"+str(page_no)\n",
    "            home_page = Request(temp_url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "            htmltext = urlopen(home_page).read()\n",
    "            home_page_soup = BS(htmltext,'html.parser')\n",
    "        \n",
    "            for d_url in home_page_soup.findAll('a', attrs={'href': re.compile(\"^\\/CA\")}):\n",
    "                d_url = d_url.get('href')\n",
    "                d_url = \"https://www.redfin.com\"+d_url\n",
    "                if (d_url not in detail_urls):\n",
    "                    detail_urls.append(d_url)\n",
    "    return (detail_urls) #returns 100 d_urls for each county (for 5 pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_data_in_df_new_listings(detail_url_list):\n",
    "    address_list=[]\n",
    "    locality_list=[]\n",
    "    region_list=[]\n",
    "    postal_code_list=[]\n",
    "    price_list=[]\n",
    "    beds_list=[]\n",
    "    baths_list=[]\n",
    "    per_sq_ft_list=[]\n",
    "    area_list=[]\n",
    "    on_redfin_list=[]\n",
    "    status_list=[]\n",
    "    built_list=[]\n",
    "    type_list=[]\n",
    "    style_list=[]\n",
    "    view_list=[]\n",
    "    community_list=[]\n",
    "    mls_list=[]\n",
    "    lot_size_list=[]\n",
    "    stories_list=[]\n",
    "    county_list=[]\n",
    "    walkable_list=[]\n",
    "    walkableScore_list=[]\n",
    "    transit_list=[]\n",
    "    transitScore_list=[]\n",
    "    bikeable_list=[]\n",
    "    bikeableScore_list=[]\n",
    "    no_of_schools_list=[]\n",
    "    \n",
    "    \n",
    "    for count in range(len(detail_url_list)):\n",
    "    #for count in range(0,80):\n",
    "        detail_url=detail_url_list[count]\n",
    "        detail_page = Request(detail_url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        htmltext = urlopen(detail_page).read()\n",
    "        text = htmltext.decode(encoding=\"utf8\", errors='ignore')\n",
    "        detail_page_soup = BS(text,'html.parser')\n",
    "    \n",
    "        address=detail_page_soup.findAll('span', attrs={'class': \"street-address\"})\n",
    "        address_list.append(address[0].get_text() if len(address)>0 else 'NA')\n",
    "\n",
    "        locality=detail_page_soup.findAll('span', attrs={'class': \"locality\"})\n",
    "        locality_list.append(locality[0].get_text() if len(locality)>0 else 'NA')\n",
    "\n",
    "        region = detail_page_soup.findAll('span', attrs={'class': \"region\"})\n",
    "        region_list.append(region[0].get_text() if len(region)>0 else 'NA')\n",
    "\n",
    "        postal_code = detail_page_soup.findAll('span', attrs={'class': \"postal-code\"})\n",
    "        \n",
    "        postal_code = detail_page_soup.findAll('span', attrs={'class': \"postal-code\"})\n",
    "        postal_code_list.append(postal_code[0].get_text() if len([postal_code])>0 else 'NA')\n",
    "\n",
    "        price = detail_page_soup.findAll('div', attrs={'class': \"statsValue\"})\n",
    "        price_list.append(price[0].get_text() if len(price)>0 else 'NA')\n",
    "\n",
    "        beds = detail_page_soup.findAll('div', attrs={'data-rf-test-id': \"abp-beds\"})\n",
    "        beds_list.append(beds[0].get_text() if len(beds)>0 else 'NA')\n",
    "\n",
    "        baths = detail_page_soup.findAll('div', attrs={'data-rf-test-id': \"abp-baths\"})\n",
    "        baths_list.append(baths[0].get_text() if len(baths)>0 else 'NA')\n",
    "            \n",
    "        per_sq_ft = detail_page_soup.findAll('div', attrs={'data-rf-test-id': \"abp-priceperft\"})\n",
    "        per_sq_ft_list.append(per_sq_ft[0].get_text() if len(per_sq_ft)>0 else 'NA')\n",
    "\n",
    "        area = detail_page_soup.findAll('span', attrs={'class': \"statsValue\"})\n",
    "        area_list.append(area[0].get_text() if len(area)>0 else 'NA')\n",
    "        \n",
    "        #Borrowed rohit's On_Redfin logic\n",
    "        on_redfin_label = detail_page_soup.findAll('span',attrs={'class':'label'})\n",
    "        on_redfin = detail_page_soup.findAll('span',attrs={'class':'value'})\n",
    "        \n",
    "        for i in range(len(on_redfin_label)):\n",
    "            if on_redfin_label[i].string is not None:\n",
    "                if 'On Redfin' in on_redfin_label[i].string:\n",
    "                    on_redfin_list.append(on_redfin[i].get_text())\n",
    "\n",
    "        status = detail_page_soup.findAll('span', attrs={'class': \"DefinitionFlyoutLink inline-block underline clickable\"})\n",
    "        status_list.append(status[0].get_text() if len(status)>0 else 'NA')\n",
    "\n",
    "\n",
    "        keyFeatures=detail_page_soup.findAll('span', attrs={'class': \"header font-color-gray-light\"})\n",
    "        valueFeatures=detail_page_soup.findAll('span', attrs={'class': \"content text-right\"})\n",
    "        key_list=[]\n",
    "        value_list=[]\n",
    "        for count in range(len(keyFeatures)):\n",
    "            key_list.append(keyFeatures[count].get_text().lower()) #changed to Lowercase\n",
    "            value_list.append(valueFeatures[count].get_text())\n",
    "    \n",
    "        #HouseType\n",
    "        type1=['type','public details','property type'] #lowercase\n",
    "        key_index=-1\n",
    "        \n",
    "        for i in range(len(type1)):\n",
    "            if type1[i] in key_list:\n",
    "                key_index=key_list.index(type1[i])\n",
    "        #made the below column names lowercase\n",
    "        type_list.append(value_list[key_index] if key_index>=0 else 'NA')\n",
    "           \n",
    "        style_list.append(value_list[key_list.index('style')] if 'style' in key_list else 'NA')\n",
    "            \n",
    "        view_list.append(value_list[key_list.index('view')] if 'view' in key_list else 'NA')\n",
    "            \n",
    "        community_list.append(value_list[key_list.index('community')] if 'community' in key_list else 'NA')\n",
    "\n",
    "        county_list.append(value_list[key_list.index('county')] if 'county' in key_list else 'NA')\n",
    "\n",
    "        mls_list.append(value_list[key_list.index('mls#')] if 'mls#' in key_list else 'NA')\n",
    "\n",
    "        built_list.append(value_list[key_list.index('built')] if 'built' in key_list else 'NA')\n",
    "\n",
    "        lot_size_list.append(value_list[key_list.index('lot size')] if 'lot size' in key_list else 'NA')\n",
    "                      \n",
    "        #Stories\n",
    "        stories_list.append(value_list[key_list.index('stories')] if 'stories' in key_list else 'NA')\n",
    "        \n",
    "       \n",
    "        \n",
    "    \n",
    "        transportMode=detail_page_soup.findAll('div', attrs={'class': \"transport-desc-and-label\"})\n",
    "        transportScore=detail_page_soup.findAll('div', attrs={'class': \"percentage\"})\n",
    "        transportKey_list=[]\n",
    "        transportValue_list=[]\n",
    "        counter=0\n",
    "        \n",
    "        for count in range(len(transportMode)):\n",
    "            transportKey_list.append(transportMode[count].get_text())\n",
    "            transportValue_list.append(transportScore[count].get_text())  \n",
    "        if any(x in transportKey_list for x in ['Very Walkable','Car-Dependent','Somewhat Walkable',\"Walker's Paradise\"]):    \n",
    "            walkable_list.append(transportKey_list[0])\n",
    "            walkableScore_list.append(transportValue_list[0])\n",
    "        else:\n",
    "            walkable_list.append('NA')\n",
    "            walkableScore_list.append('NA')\n",
    "            \n",
    "        if any(x in transportKey_list for x in ['Good Transit','Minimal Transit','Excellent Transit','Some Transit']):\n",
    "            transit_list.append(transportKey_list[1])\n",
    "            transitScore_list.append(transportValue_list[1])\n",
    "            counter=2\n",
    "        else:\n",
    "            transit_list.append('NA')\n",
    "            transitScore_list.append('NA')\n",
    "            counter=1  \n",
    "    \n",
    "        if any(x in transportKey_list for x in ['Very Bikeable','Somewhat Bikeable','Bikeable',\"Biker's Paradise\"]):    \n",
    "            bikeable_list.append(transportKey_list[counter])\n",
    "            bikeableScore_list.append(transportValue_list[counter])\n",
    "        else:\n",
    "            bikeable_list.append('NA')\n",
    "            bikeableScore_list.append('NA') \n",
    "            \n",
    "        no_of_schools=detail_page_soup.findAll('tr',attrs={'class':'schools-table-row'})\n",
    "        no_of_schools_list.append(len(no_of_schools))\n",
    "        \n",
    "    redfin_dataframe = pd.DataFrame(list(zip(address_list,locality_list,region_list,postal_code_list,price_list,beds_list,\n",
    "                                             baths_list,per_sq_ft_list,area_list,on_redfin_list,status_list,built_list,\n",
    "                                             type_list,style_list,view_list,community_list,mls_list,lot_size_list,\n",
    "                                             stories_list,county_list,walkable_list,walkableScore_list,\n",
    "                                             transit_list,transitScore_list,bikeable_list,bikeableScore_list,no_of_schools_list)),\n",
    "                                    columns=['address','locality','region','postal_code','price','beds','baths','per_sq_ft',\n",
    "                                             'area','on_redfin','status','built','type','style','view','community','mls',\n",
    "                                             'lot_size','stories','county','walkable','walkable Score','transit',\n",
    "                                             'transit score','bikeable','bikeable score','# of schools'])\n",
    "    return (redfin_dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_data_sold_property(detail_url_list):\n",
    "    address_list=[]\n",
    "    locality_list=[]\n",
    "    region_list=[]\n",
    "    postal_code_list=[]\n",
    "    estimate_price_list=[] #changed\n",
    "    sold_price_list=[] #changed\n",
    "    sold_date_list = [] #changed\n",
    "    beds_list=[]\n",
    "    baths_list=[]\n",
    "    per_sq_ft_list=[]\n",
    "    area_list=[]\n",
    "    on_redfin_list=[]\n",
    "    status_list=[]\n",
    "    built_list=[]\n",
    "    type_list=[]\n",
    "    style_list=[]\n",
    "    view_list=[]\n",
    "    community_list=[]\n",
    "    mls_list=[]\n",
    "    lot_size_list=[]\n",
    "    stories_list=[]\n",
    "    county_list=[]\n",
    "    walkable_list=[]\n",
    "    walkableScore_list=[]\n",
    "    transit_list=[]\n",
    "    transitScore_list=[]\n",
    "    bikeable_list=[]\n",
    "    bikeableScore_list=[]\n",
    "    no_of_schools_list=[]\n",
    "    \n",
    "    for count in range(len(detail_url_list)):\n",
    "    #for count in range(0,80):\n",
    "        detail_url=detail_url_list[count]\n",
    "        detail_page = Request(detail_url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        htmltext = urlopen(detail_page).read()\n",
    "        text = htmltext.decode(encoding=\"utf8\", errors='ignore')\n",
    "        detail_page_soup = BS(text,'html.parser')\n",
    "    \n",
    "        address=detail_page_soup.findAll('span', attrs={'class': \"street-address\"})\n",
    "        address_list.append(address[0].get_text() if len(address)>0 else 'NA')\n",
    "\n",
    "        locality=detail_page_soup.findAll('span', attrs={'class': \"locality\"})\n",
    "        locality_list.append(locality[0].get_text() if len(locality)>0 else 'NA')\n",
    "\n",
    "        region = detail_page_soup.findAll('span', attrs={'class': \"region\"})\n",
    "        region_list.append(region[0].get_text() if len(region)>0 else 'NA')\n",
    "        \n",
    "        postal_code = detail_page_soup.findAll('span', attrs={'class': \"postal-code\"})\n",
    "        postal_code_list.append(postal_code[0].get_text() if len([postal_code])>0 else 'NA')\n",
    "                \n",
    "        price = detail_page_soup.findAll('div', attrs={'class': \"statsValue\"})\n",
    "        estimate_price_list.append(price[0].get_text() if len(price)>0 else 'NA') #changed\n",
    "        sold_price_list.append(price[1].get_text() if len(price)>0 else 'NA') #changed\n",
    "        \n",
    "        sold_date = detail_page_soup.findAll('span',attrs={'class':'HomeSash','data-rf-test-id':'home-sash'}) #New\n",
    "        sold_date_list.append(sold_date[0].get_text()) #New\n",
    "\n",
    "        beds = detail_page_soup.findAll('div', attrs={'data-rf-test-id': \"abp-beds\"})\n",
    "        beds_list.append(beds[0].get_text() if len(beds)>0 else 'NA')\n",
    "\n",
    "        baths = detail_page_soup.findAll('div', attrs={'data-rf-test-id': \"abp-baths\"})\n",
    "        baths_list.append(baths[0].get_text() if len(baths)>0 else 'NA')\n",
    "\n",
    "        per_sq_ft = detail_page_soup.findAll('div', attrs={'data-rf-test-id': \"abp-priceperft\"})\n",
    "        per_sq_ft_list.append(per_sq_ft[0].get_text() if len(per_sq_ft)>0 else 'NA')\n",
    "\n",
    "        area = detail_page_soup.findAll('span', attrs={'class': \"statsValue\"})\n",
    "        area_list.append(area[0].get_text() if len(area)>0 else 'NA')\n",
    "    \n",
    "        built = detail_page_soup.findAll('span', attrs={'class': \"value\"})\n",
    "        on_redfin = built[2].get_text() if len(built)>2 else 'NA'\n",
    "        on_redfin_list.append(on_redfin)\n",
    "        \n",
    "        on_redfin_label = detail_page_soup.findAll('span',attrs={'class':'label'})\n",
    "        on_redfin = detail_page_soup.findAll('span',attrs={'class':'value'})\n",
    "        \n",
    "        #Borrowed rohit's On_Redfin logic\n",
    "        for i in range(len(on_redfin_label)):\n",
    "            if on_redfin_label[i].string is not None:\n",
    "                if 'On Redfin' in on_redfin_label[i].string:\n",
    "                    on_redfin_list.append(on_redfin[i].get_text())\n",
    "\n",
    "        status = detail_page_soup.findAll('span', attrs={'class': \"DefinitionFlyoutLink inline-block underline clickable\"})\n",
    "        status_list.append(status[0].get_text() if len(status)>0 else 'NA')\n",
    "\n",
    "\n",
    "        keyFeatures=detail_page_soup.findAll('span', attrs={'class': \"header font-color-gray-light\"})\n",
    "        valueFeatures=detail_page_soup.findAll('span', attrs={'class': \"content text-right\"})\n",
    "        key_list=[]\n",
    "        value_list=[]\n",
    "        for count in range(len(keyFeatures)):\n",
    "            key_list.append(keyFeatures[count].get_text().lower()) #changed to Lowercase\n",
    "            value_list.append(valueFeatures[count].get_text())\n",
    "    \n",
    "        #HouseType\n",
    "        type1=['type','public details','property type']\n",
    "        key_index=-1\n",
    "        \n",
    "        for i in range(len(type1)):\n",
    "            if type1[i] in key_list:\n",
    "                key_index=key_list.index(type1[i])\n",
    "        #made the below column names lowercase\n",
    "        type_list.append(value_list[key_index] if key_index>=0 else 'NA')\n",
    "           \n",
    "        style_list.append(value_list[key_list.index('style')] if 'style' in key_list else 'NA')\n",
    "            \n",
    "        view_list.append(value_list[key_list.index('view')] if 'view' in key_list else 'NA')\n",
    "            \n",
    "        community_list.append(value_list[key_list.index('community')] if 'community' in key_list else 'NA')\n",
    "\n",
    "        county_list.append(value_list[key_list.index('county')] if 'county' in key_list else 'NA')\n",
    "\n",
    "        mls_list.append(value_list[key_list.index('mls#')] if 'mls#' in key_list else 'NA')\n",
    "\n",
    "        built_list.append(value_list[key_list.index('built')] if 'built' in key_list else 'NA')\n",
    "\n",
    "        lot_size_list.append(value_list[key_list.index('lot size')] if 'lot size' in key_list else 'NA')\n",
    "                      \n",
    "        #Stories\n",
    "        stories_list.append(value_list[key_list.index('stories')] if 'stories' in key_list else 'NA')\n",
    "\n",
    "    \n",
    "        transportMode=detail_page_soup.findAll('div', attrs={'class': \"transport-desc-and-label\"})\n",
    "        transportScore=detail_page_soup.findAll('div', attrs={'class': \"percentage\"})\n",
    "        transportKey_list=[]\n",
    "        transportValue_list=[]\n",
    "        counter=0\n",
    "        \n",
    "        for count in range(len(transportMode)):\n",
    "            transportKey_list.append(transportMode[count].get_text())\n",
    "            transportValue_list.append(transportScore[count].get_text())  \n",
    "        if any(x in transportKey_list for x in ['Very Walkable','Car-Dependent','Somewhat Walkable',\"Walker's Paradise\"]):    \n",
    "            walkable_list.append(transportKey_list[0])\n",
    "            walkableScore_list.append(transportValue_list[0])\n",
    "        else:\n",
    "            walkable_list.append('NA')\n",
    "            walkableScore_list.append('NA')\n",
    "            \n",
    "        if any(x in transportKey_list for x in ['Good Transit','Minimal Transit','Excellent Transit','Some Transit']):\n",
    "            transit_list.append(transportKey_list[1])\n",
    "            transitScore_list.append(transportValue_list[1])\n",
    "            counter=2\n",
    "        else:\n",
    "            transit_list.append('NA')\n",
    "            transitScore_list.append('NA')\n",
    "            counter=1  \n",
    "    \n",
    "        if any(x in transportKey_list for x in ['Very Bikeable','Somewhat Bikeable','Bikeable',\"Biker's Paradise\"]):    \n",
    "            bikeable_list.append(transportKey_list[counter])\n",
    "            bikeableScore_list.append(transportValue_list[counter])\n",
    "        else:\n",
    "            bikeable_list.append('NA')\n",
    "            bikeableScore_list.append('NA')\n",
    "            \n",
    "        no_of_schools=detail_page_soup.findAll('tr',attrs={'class':'schools-table-row'})\n",
    "        no_of_schools_list.append(len(no_of_schools))\n",
    "        \n",
    "    redfin_dataframe = pd.DataFrame(list(zip(address_list,locality_list,region_list,postal_code_list,estimate_price_list,\n",
    "                                             sold_price_list,sold_date_list,beds_list,\n",
    "                                             baths_list,per_sq_ft_list,area_list,on_redfin_list,status_list,built_list,\n",
    "                                             type_list,style_list,view_list,community_list,mls_list,lot_size_list,\n",
    "                                             stories_list,county_list,walkable_list,walkableScore_list,transit_list,transitScore_list,\n",
    "                                             bikeable_list,bikeableScore_list,no_of_schools_list)),\n",
    "                                    columns=['address','locality','region','postal_code','estimate_price','sold_price_list',\n",
    "                                             'sold_date_list','beds','baths','per_sq_ft','area','on_redfin','status','built','type','style','view','community','mls',\n",
    "                                             'lot_size','stories','county','walkable','walkable Score','transit','transit score','bikeable',\n",
    "                                             'bikeable score','# of schools'])\n",
    "    return (redfin_dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_in_excel(data_frame_new,data_frame_sold):\n",
    "    writer=pd.ExcelWriter('Redfin.xlsx')\n",
    "    data_frame_new.to_excel(writer,'NewListings',index=False)\n",
    "    data_frame_sold.to_excel(writer,'SoldProperty',index=False)\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    county_url_list = []\n",
    "    detail_url_list = []\n",
    "    #BeforeT = datetime.datetime.now()\n",
    "    #Please copy the required county link from googel sheet\n",
    "    county_url_list = ['https://www.redfin.com/county/312/CA/Fresno-County/new-listings']\n",
    "                       #'https://www.redfin.com/county/313/CA/Glenn-County/new-listings',]\n",
    "                       #'https://www.redfin.com/county/317/CA/Kern-County/new-listings',]\n",
    "                      #'https://www.redfin.com/county/319/CA/Lake-County/new-listings',]\n",
    "                      #'https://www.redfin.com/county/321/CA/Los-Angeles-County/new-listings']  \n",
    "                       #getCountyUrls()   \n",
    "    \n",
    "    #for new listings\n",
    "    n_detail_url_list = getDetailUrls_NewListings(county_url_list)\n",
    "    data_frame_new = scrape_data_in_df_new_listings(n_detail_url_list)\n",
    "    \n",
    "    #for sold property\n",
    "    s_detail_url_list = getDetailUrls_SoldProperty(county_url_list)\n",
    "    data_frame_sold = scrape_data_sold_property(s_detail_url_list)\n",
    "    \n",
    "    write_in_excel(data_frame_new,data_frame_sold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
